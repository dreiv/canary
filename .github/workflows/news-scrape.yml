name: News Scraper

on:
  schedule:
    - cron: '0 * * * *' # Runs every hour
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape_news:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Scrape news and save to file
        env:
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
        run: |
          python <<EOF
          import requests
          import json
          import os
          from datetime import datetime

          api_key = os.environ.get("NEWS_API_KEY")
          url = f"https://newsapi.org/v2/top-headlines?country=us&apiKey={api_key}" # Or your country of choice.

          try:
            response = requests.get(url)
            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
            data = response.json()

            articles = data.get("articles", [])
            if articles:
              timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
              filename = f"news_scrape_{timestamp}.json"
              with open(filename, "w") as f:
                json.dump(articles, f, indent=4)
              print(f"News scraped and saved to {filename}")

            else:
              print("No articles found.")

          except requests.exceptions.RequestException as e:
            print(f"Error during request: {e}")
          except json.JSONDecodeError as e:
            print(f"Error decoding JSON: {e}")
          except Exception as e:
            print(f"An unexpected error occurred: {e}")

          EOF

      - name: Commit and push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: 'Automated news scrape'
          file_pattern: news_scrape_*.json # Only commit the json files
